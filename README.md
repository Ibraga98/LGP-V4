# ü§ü Sistema de Reconhecimento de Gestos em L√≠ngua Gestual Portuguesa (LGP)

Este reposit√≥rio apresenta um sistema desenvolvido para o reconhecimento de gestos din√¢micos em **L√≠ngua Gestual Portuguesa (LGP)**, com o objetivo de promover a inclus√£o social de pessoas surdas, facilitando a comunica√ß√£o com ouvintes atrav√©s da tradu√ß√£o de gestos em tempo real para texto.

O projeto foi desenvolvido por **Ivanilson Braga**, **Zakhar Khomyakivskyy** e **Ektiandro Elizabeth**, no √¢mbito da unidade curricular de Laboratorio De Projeto.

## üìã Descri√ß√£o Geral

A aplica√ß√£o utiliza um modelo de Deep Learning para reconhecer gestos a partir de sequ√™ncias de marcos (landmarks) da m√£o, extra√≠dos com MediaPipe. Este m√©todo √© altamente eficiente e ideal para integra√ß√£o em dispositivos m√≥veis, permitindo o reconhecimento em tempo real com baixo custo computacional.

O sistema foi treinado para reconhecer os seguintes gestos:
- **√°gua**
- **bom dia**
- **n√£o**
- **ol√°**
- **por favor**
- **sim**

## üõ† Tecnologias Utilizadas

- **Python 3.10+** ‚Äì Linguagem principal de desenvolvimento
- **TensorFlow / Keras** ‚Äì Constru√ß√£o e treino da rede neural LSTM
- **MediaPipe** ‚Äì Extra√ß√£o de marcos da m√£o a partir de imagens
- **OpenCV** ‚Äì Processamento de imagem
- **NumPy** ‚Äì Manipula√ß√£o de dados num√©ricos
- **Scikit-learn** ‚Äì Divis√£o de dados para treino e valida√ß√£o
- **TensorFlow Lite** ‚Äì Vers√£o leve do modelo para dispositivos m√≥veis

## üß† Como o modelo funciona?

O sistema abandonou a abordagem inicial de CNN (Rede Neural Convolucional) em favor de uma arquitetura mais moderna e eficiente para o reconhecimento de gestos din√¢micos: um **modelo LSTM (Long Short-Term Memory)**.

O fluxo de trabalho √© o seguinte:
1.  **Extra√ß√£o de Marcos**: Em vez de usar imagens brutas, o script `processar_dados.py` utiliza o MediaPipe para analisar cada imagem do dataset e extrair as coordenadas 3D (x, y, z) dos 21 pontos-chave da m√£o. As imagens com desenhos de esqueleto s√£o usadas apenas como fonte para gerar estes dados num√©ricos limpos.
2.  **Cria√ß√£o de Sequ√™ncias**: Os marcos extra√≠dos s√£o agrupados em sequ√™ncias de comprimento fixo (e.g., 20 frames). Estas sequ√™ncias representam a trajet√≥ria do gesto ao longo do tempo.
3.  **Treino do Modelo LSTM**: O modelo LSTM √© treinado com estas sequ√™ncias. A sua arquitetura √© especializada em aprender padr√µes temporais, tornando-o ideal para entender o movimento que define um gesto.
4.  **Convers√£o para TFLite**: O modelo treinado √© convertido para o formato `.tflite`, que √© otimizado para infer√™ncia r√°pida e de baixo consumo em dispositivos m√≥veis como Android.

Esta abordagem √© significativamente mais leve e r√°pida do que uma CNN, pois o modelo processa apenas algumas centenas de coordenadas em vez de dezenas de milhares de pixels por imagem.

## üìÇ Estrutura do Projeto

```bash
üìÅ Reconhecimento_LGP/
‚îÇ
‚îú‚îÄ‚îÄ processar_dados.py           # 1. Extrai marcos das imagens e cria o arquivo de dados.
‚îú‚îÄ‚îÄ treinar_modelo.py            # 2. Treina o modelo LSTM com os dados processados.
‚îú‚îÄ‚îÄ converter_tflite.py          # 3. Converte o modelo treinado para formato .tflite.
‚îÇ
‚îú‚îÄ‚îÄ dados_processados.npz        # Arquivo com os dados de marcos, pronto para o treino.
‚îú‚îÄ‚îÄ modelo_gestos_lgp.h5         # Modelo treinado (Keras).
‚îú‚îÄ‚îÄ modelo_gestos_lgp.tflite     # Modelo convertido para Android.
‚îú‚îÄ‚îÄ classes.json                 # Mapeamento de gestos para IDs num√©ricos.
‚îú‚îÄ‚îÄ README.md                    # Este ficheiro.
‚îî‚îÄ‚îÄ dataset_limpo/               # Dataset de imagens originais.
```

## üöÄ Como Usar o Projeto

Execute os scripts na seguinte ordem para processar os dados, treinar o modelo e convert√™-lo para uso m√≥vel.

**1. Processar o Dataset de Imagens**
Este script analisa as imagens em `dataset_limpo/`, extrai os marcos da m√£o e cria o arquivo `dados_processados.npz`.
```bash
python processar_dados.py
```

**2. Treinar o Modelo LSTM**
Este script carrega os dados processados e treina o modelo LSTM, salvando o resultado como `modelo_gestos_lgp.h5`.
```bash
python treinar_modelo.py
```

**3. Converter para TensorFlow Lite**
Este script converte o modelo `.h5` para o formato `modelo_gestos_lgp.tflite`, que est√° pronto para ser usado na aplica√ß√£o Android.
```bash
python converter_tflite.py
```

---
## ü§ñ Aplica√ß√£o Android

A vers√£o m√≥vel da aplica√ß√£o, localizada na pasta `Reconhecimento_LGP_Android/`, foi desenvolvida em **Kotlin** com **Jetpack Compose** e utiliza os seguintes componentes:
- **CameraX**: Para uma implementa√ß√£o robusta da c√¢mara.
- **MediaPipe (Tasks Vision)**: Para extrair os marcos da m√£o em tempo real.
- **TensorFlow Lite**: Para executar o modelo `modelo_gestos_lgp.tflite` e fazer a infer√™ncia.

O processamento √© todo feito no dispositivo, usando a c√¢mara para interpretar os gestos em tempo real com baixa lat√™ncia.

### üöÄ Como Usar a Aplica√ß√£o Android

1.  **Abrir no Android Studio**:
    *   Abra o Android Studio.
    *   Selecione `File > Open` e navegue at√© √† pasta `Reconhecimento_LGP_Android`.
    *   Aguarde o **Gradle Sync** terminar. Este processo descarrega todas as depend√™ncias necess√°rias.

2.  **Selecionar o Dispositivo**:
    *   No topo da janela, escolha um dispositivo (f√≠sico ou emulador) no menu dropdown.
    *   Para usar um telem√≥vel f√≠sico, ative as "Op√ß√µes de Programador" e a "Depura√ß√£o USB".

3.  **Executar a Aplica√ß√£o**:
    *   Clique no √≠cone verde de "Run 'app'" (‚ñ∂Ô∏è) ou use o atalho `Shift + F10`.
    *   A aplica√ß√£o ser√° instalada e iniciada no dispositivo selecionado.

> **Nota sobre a Vers√£o do AGP**: O projeto foi configurado com a vers√£o `8.4.1` do Android Gradle Plugin. Se o seu Android Studio sugerir uma atualiza√ß√£o (ex: para `8.11`), pode aceit√°-la. Desde que o Gradle Sync seja conclu√≠do com sucesso, a aplica√ß√£o funcionar√° corretamente.

## üë• Contribuidores

- **Ivanilson Braga**
- **Zakhar Khomyakivskyy**
- **Ektiandro Elizabeth**

## üßæ Licen√ßa

Projeto desenvolvido para fins acad√©micos no √¢mbito da unidade curricular de Projeto.
Qualquer reutiliza√ß√£o parcial ou total deve referenciar os autores.

